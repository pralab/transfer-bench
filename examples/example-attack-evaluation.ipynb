{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AttackEval class for evaluating the performance on defaults scenarios\n",
    "\n",
    "Example of usage of the TransferBench library to evaluate the attack performance of on an adversarial attacks on preset or custom scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# case 1: Evaluate Attack using a default scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transferbench.attack_evaluation import AttackEval\n",
    "from transferbench.attacks_zoo import NaiveAvg\n",
    "\n",
    "evaluator = AttackEval(NaiveAvg)\n",
    "# Default scenarios are:\n",
    "print(evaluator.scenarios)\n",
    "# Running the evaluation\n",
    "result = evaluator.run(batch_size=4, device=\"cuda:1\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: Evaluate Attack using custom scenarios, on torchvision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transferbench.attack_evaluation import AttackEval\n",
    "from transferbench.attacks_zoo import NaiveAvg\n",
    "from transferbench.scenarios import list_scenarios\n",
    "\n",
    "evaluator = AttackEval(NaiveAvg)\n",
    "# try another default scenario from the list\n",
    "print(list_scenarios())\n",
    "evaluator.set_scenarios(\"homo-imagenet-inf\")\n",
    "result = evaluator.run(batch_size=4, device=\"cuda:1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3\n",
    "\n",
    "### Evaluating on a highly personalizable scenarios with custom models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from transferbench.attack_evaluation import AttackEval\n",
    "from transferbench.attacks_zoo import NaiveAvg\n",
    "from transferbench.models.utils import add_normalization\n",
    "from transferbench.scenarios import AttackScenario, HyperParameters\n",
    "from transferbench.types import TransferAttack\n",
    "\n",
    "# Load a dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "cifar100 = datasets.CIFAR100(\n",
    "    root=\"./data/datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "cifar100_mean = [0.5, 0.5, 0.5]\n",
    "cifar100_std = [1.0, 1.0, 1.0]\n",
    "\n",
    "REPO_LINK = \"chenyaofo/pytorch-cifar-models\"\n",
    "# Load models and normalize them\n",
    "def get_model(model):\n",
    "    return torch.hub.load(\n",
    "    REPO_LINK, \"cifar100_\" + model, pretrained=True\n",
    ")\n",
    "\n",
    "# Use the dataset in the TransferEval\n",
    "victim_model = add_normalization(get_model(\"resnet56\"), cifar100_mean, cifar100_std)\n",
    "surrogate_models = [\n",
    "    add_normalization(get_model(\"vgg11_bn\"), cifar100_mean, cifar100_std),\n",
    "    add_normalization(get_model(\"vgg13_bn\"), cifar100_mean, cifar100_std),\n",
    "    add_normalization(get_model(\"vgg16_bn\"), cifar100_mean, cifar100_std),\n",
    "    add_normalization(get_model(\"vgg19_bn\"), cifar100_mean, cifar100_std),\n",
    "]\n",
    "\n",
    "def my_transfer_attack(\n",
    "    victim_model,\n",
    "    surrogate_models,\n",
    "    inputs,\n",
    "    labels,\n",
    "    targets=None,\n",
    "    eps=None,\n",
    "    p=None,\n",
    "    maximum_queries=None,\n",
    "):\n",
    "    return inputs #:)\n",
    "\n",
    "# Be sure that the attack signature is correct ->\n",
    "print(f\"Is signature correct? {isinstance(my_transfer_attack, TransferAttack)}\") \n",
    "\n",
    "myscenario = AttackScenario(\n",
    "    hp=HyperParameters(eps=0.3, p=2, maximum_queries=10),\n",
    "    victim_model=victim_model,\n",
    "    surrogate_models=surrogate_models,\n",
    "    transfer_attack=my_transfer_attack,\n",
    "    dataset=cifar100,\n",
    ")\n",
    "evaluator = AttackEval(NaiveAvg)\n",
    "evaluator.set_scenarios(myscenario)\n",
    "result = evaluator.run(batch_size=4, device=\"cuda:1\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TransfBench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
